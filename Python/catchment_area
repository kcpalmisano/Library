# -*- coding: utf-8 -*-
"""
Created on Wed Jan 31 11:24:28 2023

@author: cpalmisano
"""

from datetime import datetime
from geopy.geocoders import Nominatim
import pandas as pd
import gc
import inspect
from datetime import date
import pyodbc
import sqlalchemy
from sqlalchemy.orm import sessionmaker
import math
import geopy.distance
from geopy.distance import great_circle

#!!!


def close_all_connections():
    """
    This function will close all open connections
    """
    for obj in gc.get_objects():
        if inspect.ismodule(obj):
            for name in dir(obj):
                if name == "engine":
                    engine = getattr(obj, name)
                    if isinstance(engine, sqlalchemy.engine.Engine):
                        engine.dispose()
                elif name == "conn":
                    conn = getattr(obj, name)
                    if conn is not None and isinstance(conn, pyodbc.Connection):
                        try:
                            conn.close()
                        except pyodbc.ProgrammingError:
                            pass
                elif name == "con":
                    con = getattr(obj, name)
                    if con is not None and isinstance(con, pyodbc.Connection):
                        try:
                            con.close()
                        except pyodbc.ProgrammingError:
                            pass
                elif name == "cursor":
                    cursor = getattr(obj, name)
                    if cursor is not None and isinstance(cursor, pyodbc.Cursor):
                        try:
                            cursor.close()
                        except pyodbc.ProgrammingError:
                            pass


# Connection
def connect_to_sql_server(server_name, database_name):
    # connect via pyodbc
    conn = pyodbc.connect(
        f'Driver={{SQL Server}};Server={server_name};Database={database_name};Trusted_Connection=yes;')

    # connect via sqlalchemy
    con = sqlalchemy.create_engine(
        f'mssql://{server_name}/{database_name}?trusted_connection=yes&driver=ODBC+Driver+17+for+SQL+Server', fast_executemany=True)

    return conn, con

# ------------------------------------------------------ #!!!


# connection to server -> SERVER   db -> DATABASE
conn, con = connect_to_sql_server('SERVER', 'DATABASE')
cursor = conn.cursor()
conn.autocommit = True

con = sqlalchemy.create_engine(
    'mssql://SERVER/DATABASE?trusted_connection=yes&driver=ODBC+Driver+17+for+SQL+Server', fast_executemany=True)
Session = sessionmaker(bind=con)
session = Session()

# SQL query to fetch data from the database
coe_locs = pd.read_sql("""
SELECT funds_coetype, funds_coetypename, funds_name, funds_address1_postalcode as zip, funds_fein
, funds_address1_line1 + ' ' + funds_address1_city + ', ' +  funds_address1_stateorprovince + ' ' + funds_address1_postalcode  as Address
, NULL as latitude, NULL as longitude
FROM [funds_providerorganization]
  WHERE funds_parentorganization IS NULL and funds_coetype IS NOT NULL
""", con)


#!!!

# Initialize Nominatim geocoder with user_agent header
geolocator = Nominatim(user_agent="coe_facilities")

# Extract addresses and convert to strings
addresses = coe_locs['Address'].apply(str).tolist()

# Create an empty list to store zip codes within 50 miles radius
zip_codes_in_radius = []

# 1-1 hopsital lat/long from google maps based on address
# Current hardcode as of 4/24/2024
hospitals = [
    (42.250606, -71.078271),  # BETH ISRAEL DEACONESS MILTON
    (40.462253, -79.946908),  # WEST PENN HOSPITAL
    (42.466401, -71.123150),  # WINCHESTER HOSPITAL
    (40.805544, -73.961967),  # MOUNT SINAI MORNINGSIDE
    (41.774682, -72.699529),  # SAINT FRANCIS HOSPITAL AND MEDICAL CENTER
    (26.187342, -80.120705),  # HOLY CROSS HEALTH - FORT LAUDERDALE
    (40.428361, -79.748843),  # FORBES HOSPITAL
    (41.552679, -73.035679),  # SAINT MARYS HOSPITAL
    (40.965055, -74.072562),  # THE VALLEY HOSPITAL updated 4/24/2024
    (40.435682, -79.766520),  # MONROEVILLE SURGERY CENTER
    (42.111765, -80.079800),  # ST VINCENT HOSPITAL
    (40.635625, -80.064512),  # WEXFORD HOSPITAL
    (40.635625, -80.064512),  # WEXFORD SURGERY CENTER
    (40.770071, -73.987758),  # MOUNT SINAI WEST
    (26.195650, -80.133656),  # PHYSICIANS OUTPATIENT SURGERY CENTER
    (42.400935, -71.279475),  # BOSTON OUTPATIENT SURGICAL SUITES
    (42.330175, -71.107233),  # NEW ENGLAND BAPTIST HOSPITAL
    (39.957740, -75.200006),  # PENN PRESBYTERIAN MEDICAL CENTER
    (39.944693, -75.156461),  # PENNSYLVANIA HOSPITAL
    (39.944693, -75.156461)]  # PENNSYLVANIA HOSPITAL


# one-to-one mapping of lat/long
coe_locs[["latitude", "longitude"]] = pd.DataFrame(
    hospitals, columns=["latitude", "longitude"])


df = coe_locs

#!!!
# # load in all zip codes
# zips = pd.read_excel(
#     r'C:/Users/cpalmisano/PATH/Ad Hoc/zip_codes.xlsx')


zips = pd.read_sql('''
                   select distinct ZipCode as zip, Latitude as latitude, Longitude as longitude
                     from main.zipcodes
                   ''', con)

# # fill missing zeros in zipcode due to Excel being bitchy
# zips['zip'] = zips['zip'].apply(lambda x: '{:05d}'.format(x))


# Initialize Nominatim geocoder with user_agent header
geocoder = Nominatim(user_agent="coe_facilities")

# Define the 50-mile radius in kilometers
radius_km = 50

# Iterate through each address
for index, row in df.iterrows():
    address_lat = row["latitude"]
    address_long = row["longitude"]

    # Select potential zip codes efficiently
    filtered_zips = zips[
        (zips["latitude"] >= address_lat - radius_km / 111.11) &
        (zips["latitude"] <= address_lat + radius_km / 111.11) &
        (zips["longitude"] >= address_long - radius_km / (111.11 * math.cos(address_lat * math.pi / 180))) &
        (zips["longitude"] <= address_long + radius_km /
         (111.11 * math.cos(address_lat * math.pi / 180)))
    ]

    # Calculate distances and filter within radius
    zip_distances = []
    for i, zip_row in filtered_zips.iterrows():
        zip_lat = zip_row["latitude"]
        zip_long = zip_row["longitude"]
        distance = great_circle(
            (address_lat, address_long), (zip_lat, zip_long)).km
        if distance <= radius_km:
            zip_distances.append((distance, zip_row["zip"]))

    # Sort zip codes by distance and store as comma-separated string
    zip_distances.sort(key=lambda x: x[0])
    df.loc[index, "zip_codes_in_radius"] = ", ".join(
        [str(code) for _, code in zip_distances])


# Add updated date
today = datetime.today().date()
df['date_updated'] = pd.to_datetime(today)

#!!!  all listed member zip codes 
sql = pd.read_sql('''
select distinct memberzipcode as zip
 from ClaimsData
order by memberzipcode desc
''', con)





# Concatenate DataFrames and assign the result
all_zips = pd.concat([zips, sql], join='outer', ignore_index=True)

# Filter and clean zip codes (optional)
if not all_zips.empty:  # Check if 'all_zips' is not empty
    all_zips = all_zips.dropna()
    all_zips = all_zips.drop_duplicates()



# Extract zip codes, strip spaces, and create a DataFrame
additional_column_name = 'funds_coetype'  # Replace with the actual column name

zip_codes_df = pd.DataFrame({
    'all_zip_codes': [
        [item.strip() for item in sublist if item]  # Existing zip code processing
        for sublist in df['zip_codes_in_radius'].str.split(',')
    ],
    additional_column_name: df[additional_column_name].tolist()  # Access the additional column
})



# create dataframe with zips and coe type
exploded_df = zip_codes_df.explode('all_zip_codes')  # Explode 'zips' column into separate rows


if exploded_df.empty:
    # Handle empty DataFrame scenario (e.g., assign False to 'catchment' column)
    zips['catchment'] = False
else:
    # Use vectorized operations for efficiency
    zips['catchment'] = zips['zip'].isin(exploded_df['all_zip_codes'])


# check to see counts 
counts = zips['catchment'].value_counts()

#change to 1 / 0 
zips['catchment'] = zips['catchment'].astype(int)

#bring together
merged_df = pd.merge(zips, exploded_df, left_on='zip', right_on='all_zip_codes', how='left')

#Drop extra zip column
merged_df = merged_df.drop(['all_zip_codes',  'latitude', 'longitude'], axis=1)

# Change to 1 / 0 boolean 
merged_df['catchment'] = merged_df['catchment'].astype(int)


#!!!
# Insert data into SQL Server
conn.commit()

try:
    df.to_sql('COE_CatchmentZips', con, schema='SCHEMA',
              index=False, chunksize=1000, if_exists='replace')

except:
    print('load faild')

finally:
    print("Catchment Loaded")


try:
    merged_df.to_sql('CatchmentZips', con, schema='SCHEMA',
              index=False, chunksize=1000, if_exists='replace')

except:
    print('load failed')

finally:
    print("Catchment Loaded")


# close all connections
try:
    close_all_connections()
    session.close()

except:
    print('session close failed')

finally:
    print('session closed')

